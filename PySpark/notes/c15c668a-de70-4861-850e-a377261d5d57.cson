createdAt: "2019-11-11T12:17:14.556Z"
updatedAt: "2019-11-11T12:44:07.923Z"
type: "MARKDOWN_NOTE"
folder: "bc2389d69e5c7a9e3a3b"
title: "Basics"
tags: [
  "schema"
  "select"
  "new_column"
  "sql"
]
content: '''
  # 
  # Basics
  ### Import spark module and create the session
  ```python
  from pyspark.sql import SparkSession
  spark = SparkSession.builder.appName('Basics').getOrCreate()
  ```
  ### Read in the Data, inspect, and printSchema
  ```python
  df = spark.read.json('people.json')
  df.show()
  df.printSchema()
  df.columns
  # Similar to pandas .describe -- must have .show()
  df.describe().show()
  ```
  ### Create a list of structure fields
  ```python
  from pyspark.sql.types import StructField,StringType,IntegerType,StructType
  # create a schema
  data_schema = [StructField('age',IntegerType(),True),
                 StructField('name',StringType(),True)]
  final_struc = StructType(fields=data_schema)
  # read in the data using the new schema
  df = spark.read.json('people.json',schema=final_struc)
  df.printSchema()
  df.show()
  type(df['age']) # returns the column object, which type proves
  ```
  ### Select columns and print their types
  ```python
  df.select('age').show()
  print(type(df.select('age')))
  # Select two columns
  df.select(['age','name']).show()
  # returns a list of row objects - 0 selects first object
  df.head(2)[0] 
  ```
  ### Create a new column 'double_age' by copying the 'age' column object and multiplying by 2
  ### This is not an inplace operation, to save you must create new variable
  ```python
  df.withColumn('double_age',df['age']*2).show()
  df.withColumnRenamed('age','my_new_age').show()
  ```
  ### Spark SQL syntax in pyspark
  ```python
  results = spark.sql("SELECT * FROM people")
  results.show()
  new_results = spark.sql("SELECT * FROM people WHERE age=30")
  new_results.show()
  ```
'''
linesHighlighted: []
isStarred: false
isTrashed: false
