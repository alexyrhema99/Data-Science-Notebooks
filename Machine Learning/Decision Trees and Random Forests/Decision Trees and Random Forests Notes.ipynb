{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Node = The node that performs the first split\n",
    "### Leaf Nodes = Terminal nodes that predict the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To improve performance, we can use many trees with a random sample of features chosen as the split.\n",
    "- A new random sample of features is chosen for every single tree at every single split.\n",
    "- For classification, m is typically chosen to be the square root of p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging is a general purpose procedure for reducing the variance of a machine learning method.\n",
    "#### When using \"bagged trees,\" if there is one very strong feature in the data set, most of the trees will use that feature as the top split, resulting in an ensemble of trees that are highly correlated (which we don't want). \n",
    "- Averaging highly correlated quantities does not significantly reduce variance.\n",
    "- By randomly leaving out candidate features from each split, Random Forests \"decorrelates\" the trees, such that the averaging process can reduce the variance of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
